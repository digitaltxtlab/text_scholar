filename <- '/home/kln/stopwords_eng.txt'
stopfil <- scan(filename, what="character", sep=NULL)
idx <- rep(NA,length(types))
for(i in 1:length(types)){idx[i] <- match(types[i], stopfil)}
types2exclude <- stopfil[idx[!is.na(idx)]]
dim(main.mat)
save(main.mat, file = '/home/kln/projects/loevschal/auto_indexer/data/vspc746d.RData')
# LDA
rm(list = ls())
wd <- '/home/kln/Documents/education/text_scholar'
setwd(wd)
source('code.R/util_fun.R')
# necessary
library(tm)
library(topicmodels)
books.cor  <- Corpus(DirSource('data/txt/', encoding = "UTF-8"), readerControl = list(language = "lat"))
names(books.cor) <- gsub("\\..*","",names(books.cor))# remove ending
filenames <- names(books.cor)
books.cor <- tm_map(books.cor, PlainTextDocument)
books.cor <- tm_map(books.cor, content_transformer(tolower))
books.cor <- tm_map(books.cor, removePunctuation)
books.cor <- tm_map(books.cor, removeNumbers)
books.cor <- tm_map(books.cor, removeWords, stopwords("danish"))
#books.cor <- tm_map(books.cor, stemDocument)
books.cor <- tm_map(books.cor, stripWhitespace)
# document term matrix
books.dtm <- DocumentTermMatrix(books.cor, control = list(minWordLength = 2))
dim(books.dtm)
books.dtm <- docsparse(2,books.dtm)
dim(books.dtm)
books.dtm <- prune(books.dtm,.75,1)
summary(col_sums(books.dtm))
dim(books.dtm)
summary(col_sums(books.dtm))
books.dtm <- docsparse(2,books.dtm)
dim(books.dtm)
summary(col_sums(books.dtm))
library(slam)
dim(books.dtm)
summary(col_sums(books.dtm))
books.dtm <- prune(books.dtm,.75,1)
summary(col_sums(books.dtm))
mdl <- LDA(books.dtm, 20)
save.image('data/lda.RData')
load('data/lda.RData')
View(capname)
inspect(topicmodels)
ls("package:topicmodels")
get_terms(mdl,10)
# LDA
rm(list = ls())
wd <- '/home/kln/Documents/education/text_scholar'
setwd(wd)
source('code.R/util_fun.R')
# necessary
library(tm)
library(topicmodels)
library(slam)
# build corpus
books.cor  <- Corpus(DirSource('data/txt/', encoding = "UTF-8"), readerControl = list(language = "lat"))
names(books.cor) <- gsub("\\..*","",names(books.cor))# remove ending
filenames <- names(books.cor)
books.cor <- tm_map(books.cor, PlainTextDocument)
books.cor <- tm_map(books.cor, content_transformer(tolower))
books.cor <- tm_map(books.cor, removePunctuation)
books.cor <- tm_map(books.cor, removeNumbers)
books.cor <- tm_map(books.cor, removeWords, stopwords("danish"))
#books.cor <- tm_map(books.cor, stemDocument)
books.cor <- tm_map(books.cor, stripWhitespace)
# document term matrix
books.dtm <- DocumentTermMatrix(books.cor, control = list(minWordLength = 2))
dim(books.dtm)
books.dtm <- docsparse(2,books.dtm)
mdl <- LDA(books.dtm, 20)
get_terms(mdl,10)
# LDA
rm(list = ls())
wd <- '/home/kln/Documents/education/text_scholar'
setwd(wd)
source('code.R/util_fun.R')
# necessary
library(tm)
library(topicmodels)
library(slam)
# build corpus
books.cor  <- Corpus(DirSource('data/txt/', encoding = "UTF-8"), readerControl = list(language = "lat"))
names(books.cor) <- gsub("\\..*","",names(books.cor))# remove ending
filenames <- names(books.cor)
books.cor <- tm_map(books.cor, PlainTextDocument)
books.cor <- tm_map(books.cor, content_transformer(tolower))
books.cor <- tm_map(books.cor, removePunctuation)
books.cor <- tm_map(books.cor, removeNumbers)
books.cor <- tm_map(books.cor, removeWords, stopwords("danish"))
#books.cor <- tm_map(books.cor, stemDocument)
books.cor <- tm_map(books.cor, stripWhitespace)
# document term matrix
books.dtm <- DocumentTermMatrix(books.cor, control = list(minWordLength = 2))
dim(books.dtm)
books.dtm <- prune(books.dtm,0,.98)
dim(books.dtm)
View(prune)
View(prune)
dtm = books.dtm
mx <- ceiling(dim(dtm)[1]*mx)
dim(dtm)[1]
mx = 98
mx <- ceiling(dim(dtm)[1]*mx)
mx
mx = 1
mx <- ceiling(dim(dtm)[1]*mx)
mx
books.dtm <- prune(books.dtm,.98,0)
dtm <- dtm[,slam::col_sums(as.matrix(dtm) > 0) < mx]
mx = .98
mx <- ceiling(dim(dtm)[1]*mx)
dtm <- dtm[,slam::col_sums(as.matrix(dtm) > 0) < mx]
slam::col_sums(as.matrix(dtm) > 0)
as.matrix(dtm)
dtm = books.dtm
mx = .98
mx <- ceiling(dim(dtm)[1]*mx)
mx
dtm <- dtm[,slam::col_sums(as.matrix(dtm) > 0) < mx]
as.matrix(dtm)
dtm
books.dtm <- DocumentTermMatrix(books.cor, control = list(minWordLength = 2))
dtm = books.dtm
mx = .98
mx <- ceiling(dim(dtm)[1]*mx)
mx
dtm <- dtm[,slam::col_sums(as.matrix(dtm) > 0) < mx]
prune <- function(dtm,mxper,mnper = 0){
mx <- ceiling(dim(dtm)[1]*mx)
dtm <- dtm[,slam::col_sums(as.matrix(dtm) > 0) < mx]
dtm <- dtm[,col_sums(dtm) < quantile(slam::col_sums(dtm),mnper)]
return(dtm)
}
books.dtm <- prune(books.dtm,.98,0)
dim(books.dtm)
dtm = books.dtm
books.dtm <- DocumentTermMatrix(books.cor, control = list(minWordLength = 2))
dim(books.dtm)
#books.dtm <- docsparse(2,books.dtm)
dtm = books.dtm
test <- prune(books.dtm,1,0)
books.dtm <- DocumentTermMatrix(books.cor, control = list(minWordLength = 2))
dtm = books.dtm
x = as.matrx(dtm)
x = as.matrix(dtm)
x[,1]
x[,2]
max(x[,2])
prune <- function(dtm,mxper,mnper = 0){
mx <- ceiling(dim(dtm)[1]*mx)
dtm <- dtm[,slam::col_sums(as.matrix(dtm) > 0) < mx]
dtm <- dtm[,col_sums(dtm) < quantile(slam::col_sums(dtm),mnper)]
return(dtm)
}
test <- prune(books.dtm,1,0)
dtm = books.dtm
mx = .98
mx <- ceiling(dim(dtm)[1]*mx)
dtm = books.dtm
dtm = books.dtm
mx <- ceiling(dim(dtm)[1]*mx)
mx
dtm = books.dtm
dim(dtm)
mx <- ceiling(dim(dtm)[1]*mx)
mx
dim(dtm)
dtm = books.dtm
prune <- function(dtm,mxper,mnper){
mxper <- ceiling(dim(dtm)[1]*mxper)
dtm <- dtm[,slam::col_sums(as.matrix(dtm) > 0) < mxper]
dtm <- dtm[,col_sums(dtm) < quantile(slam::col_sums(dtm),mnper)]
return(dtm)
}
dim(dtm)
test <- prune(dtm,1,0)
mxper = 1
mnper = 0
mxper <- ceiling(dim(dtm)[1]*mxper)
mxper
slam::col_sums(as.matrix(dtm) > 0)
slam::col_sums(as.matrix(dtm) > 0) < mxper
max(x[,2])
slam::col_sums(as.matrix(dtm) > 0) < mxper
dtm[,slam::col_sums(as.matrix(dtm) > 0) <= mxper]
mat = as.matrix(dtm)
mxper = 1
mnper = 0
mxper <- ceiling(dim(dtm)[1]*mxper)
mat = as.matrix(dtm)
slam::col_sums(mat)
mxidx =  slam::col_sums(mat) <= mxper
mxidx
mnidx =  slam::col_sums(mat) >= mnper
tmp = slam::col_sums(mat)
tmp
freq = slam::col_sums(mat)
per = quantile(freq, tmp(mnper, mxper))
freq = slam::col_sums(mat)
per = quantile(freq, c(mnper, mxper))
mnper
mxper
freq
freq = slam::col_sums(dtm)
freq
per = quantile(freq, c(mnper, mxper))
freq
mnper
mxper
mxper = 1
mnper = 0
freq = slam::col_sums(dtm)
per = quantile(freq, c(mnper, mxper))
per
per[1]
mnidx = freq >= per[1]
mnidx
mnidx = freq >= per[1]
mxidx = freq <= per[2]
per[1]
mnidx|mxidx
sum(mnidx|mxidx)
mxper = .98
mnper = 0
freq = slam::col_sums(dtm)
per = quantile(freq, c(mnper, mxper))
mnidx = freq >= per[1]
mxidx = freq <= per[2]
sum(mnidx|mxidx)
mxper = 1
mnper = 0
freq = slam::col_sums(dtm)
per = quantile(freq, c(mnper, mxper))
mnidx = freq >= per[1]
mxidx = freq <= per[2]
sum(mnidx|mxidx)
mat = as.matrix(dtm)
mxidx =  slam::col_sums(mat) <= mxper
mnidx =  slam::col_sums(mat) >= mnper
sum(mxidx&mnidx)
mxper = 1
mnper = 0
dtm = books.dtm
mxper = 1
mnper = 0
freq = slam::col_sums(dtm)
dtm = books.dtm
mxper = 1
mnper = 0
freq = slam::col_sums(dtm)
per = quantile(freq, c(mnper, mxper))
mnidx = freq >= per[1]
mxidx = freq <= per[2]
sum(mnidx & mxidx)
dtm = books.dtm
mxper = .98
mnper = 0
freq = slam::col_sums(dtm)
per = quantile(freq, c(mnper, mxper))
mnidx = freq >= per[1]
mxidx = freq <= per[2]
sum(mnidx & mxidx)
dtm = books.dtm
dim(dtm)
mxper = 100
mnper = 0
freq = slam::col_sums(dtm)
per = quantile(freq, c(mnper, mxper))
mnidx = freq >= per[1]
mxidx = freq <= per[2]
idx = mnidx & mxidx
dtm = dtm[,idx]
dtm = books.dtm
dim(dtm)
mxper = 1
mnper = 0
freq = slam::col_sums(dtm)
per = quantile(freq, c(mnper, mxper))
mnidx = freq >= per[1]
mxidx = freq <= per[2]
idx = mnidx & mxidx
dtm = dtm[,idx]
dim(dtm)
mxper = .98
mnper = 0
freq = slam::col_sums(dtm)
per = quantile(freq, c(mnper, mxper))
mnidx = freq >= per[1]
mxidx = freq <= per[2]
idx = mnidx & mxidx
dtm = dtm[,idx]
dim(dtm)
prune <- funtion(dtm, mxper, mnper = 0){
freq = slam::col_sums(dtm)
per <- quantile(freq, c(mnper,mxper))
idx <- freq >= per[1] & freq <= per[2]
dtm = dtm[,idx]
return(dtm)
}
prune <- funtion(dtm, mxper, mnper = 0){
freq <- slam::col_sums(dtm)
per <- quantile(freq, c(mnper,mxper))
idx <- (freq >= per[1]) & (freq <= per[2])
dtm = dtm[,idx]
return(dtm)
}
freq <- slam::col_sums(dtm)
per <- quantile(freq, c(mnper,mxper))
per
freq <- slam::col_sums(dtm)
freq <- slam::col_sums(as.matrix(dtm))
freq
mxper = .98
mnper = 0
freq <- slam::col_sums(as.matrix(dtm))
per <- quantile(freq, c(mnper,mxper))
per
dtm = books.dtm
dim(dtm)
mxper = .98
mxper = 1
mnper = 0
freq <- slam::col_sums(as.matrix(dtm))
per <- quantile(freq, c(mnper,mxper))
per
mxper = .98
mnper = 0
freq <- slam::col_sums(as.matrix(dtm))
freq
per <- quantile(freq, c(mnper,mxper))
per
idx <- (freq >= per[1]) & (freq <= per[2])
dtm = dtm[,idx]
return(dtm)
prune <- funtion(dtm, mxper, mnper = 0){
freq <- slam::col_sums(as.matrix(dtm))
per <- quantile(freq, c(mnper,mxper))
idx <- (freq >= per[1]) & (freq <= per[2])
dtm = dtm[,idx]
return(dtm)
}
prune <- funtion(dtm, mxper, mnper = 0){
freq <- slam::col_sums(as.matrix(dtm))
per <- quantile(freq, c(mnper,mxper))
idx <- (freq >= per[1]) & (freq <= per[2])
dtm = dtm[,idx]
return(dtm)
}
prune <- function(dtm, mxper, mnper = 0){
freq <- slam::col_sums(as.matrix(dtm))
per <- quantile(freq, c(mnper,mxper))
idx <- (freq >= per[1]) & (freq <= per[2])
dtm = dtm[,idx]
return(dtm)
}
dtm = books.dtm
dim(dtm)
prune <- function(dtm, mxper, mnper = 0){
freq <- slam::col_sums(as.matrix(dtm))
per <- quantile(freq, c(mnper,mxper))
idx <- (freq >= per[1]) & (freq <= per[2])
dtm = dtm[,idx]
return(dtm)
}
test <- prune(dtm,1,0)
dim(test)
test <- prune(dtm,.98,0)
dim(test)
books.dtm <- DocumentTermMatrix(books.cor, control = list(minWordLength = 2))
dim(books.dtm)
#books.dtm <- docsparse(2,books.dtm)
# prune dtm
prune <- function(dtm, mxper, mnper = 0){
freq <- slam::col_sums(as.matrix(dtm))
per <- quantile(freq, c(mnper,mxper))
idx <- (freq >= per[1]) & (freq <= per[2])
dtm = dtm[,idx]
return(dtm)
}
books.dtm <- prune(books.dtm,.98)
dim(books.dtm)
# LDA
rm(list = ls())
wd <- '/home/kln/Documents/education/text_scholar'
setwd(wd)
source('code.R/util_fun.R')
# necessary
library(tm)
library(topicmodels)
library(slam)
# build corpus
books.cor  <- Corpus(DirSource('data/txt/', encoding = "UTF-8"), readerControl = list(language = "lat"))
names(books.cor) <- gsub("\\..*","",names(books.cor))# remove ending
filenames <- names(books.cor)
books.cor <- tm_map(books.cor, PlainTextDocument)
books.cor <- tm_map(books.cor, content_transformer(tolower))
books.cor <- tm_map(books.cor, removePunctuation)
books.cor <- tm_map(books.cor, removeNumbers)
books.cor <- tm_map(books.cor, removeWords, stopwords("danish"))
#books.cor <- tm_map(books.cor, stemDocument)
books.cor <- tm_map(books.cor, stripWhitespace)
# document term matrix
books.dtm <- DocumentTermMatrix(books.cor, control = list(minWordLength = 2))
dim(books.dtm)
#books.dtm <- docsparse(2,books.dtm)
# prune dtm
prune <- function(dtm, mxper, mnper = 0){
freq <- slam::col_sums(as.matrix(dtm))
per <- quantile(freq, c(mnper,mxper))
idx <- (freq >= per[1]) & (freq <= per[2])
dtm = dtm[,idx]
return(dtm)
}
books.dtm <- prune(books.dtm,.98)
dim(books.dtm)
install.packages("tictoc", dependencies = TRUE)
library(tictoc)
tic()
mdl <- LDA(books.dtm, 20)
toc()
816/60
get_terms(mdl,10)
set.seed(23)
mdl <- LDA(books.dtm, 20)
dim(books.dtm)
save.image('data/lda.RData')
load('data/lda.RData')
get_terms(mdl,10)
# LDA
rm(list = ls())
wd <- '/home/kln/Documents/education/text_scholar'
setwd(wd)
source('code.R/util_fun.R')
load('data/lda.RData')
ls("package:topicmodels")
get_terms(mdl,10)
ls("package:topicmodels")
get_topics(mdl,10)
books.cor  <- Corpus(DirSource('data/txt/', encoding = "UTF-8"), readerControl = list(language = "lat"))
names(books.cor) <- gsub("\\..*","",names(books.cor))# remove ending
filenames <- names(books.cor)
names(books.cor)
books.cor  <- Corpus(DirSource('data/txt/', encoding = "UTF-8"), readerControl = list(language = "lat"))
library(tm)
library(topicmodels)
library(slam)
# build corpus
books.cor  <- Corpus(DirSource('data/txt/', encoding = "UTF-8"), readerControl = list(language = "lat"))
names(books.cor) <- gsub("\\..*","",names(books.cor))# remove ending
names(books.cor)
get_topics(mdl,10)
topicdist <- get_topics(mdl,10)
names(topicdist)
colnames(topicdist)
colnames(topicdist) <- names(books.cor)
topicdist
worddist <- get_terms(mdl,10)
worddist
ls("package:topicmodels")
library(XML)
url = 'http://www.biblestudytools.com/job/'
doc.html = htmlTreeParse(url,
useInternal = TRUE)
library(XML)
# read and parse html file
# no noise
url = 'http://apiolaza.net/babel'
doc.html = htmlTreeParse(url,
useInternal = TRUE)
doc.text = unlist(xpathApply(doc.html, '//p', xmlValue))
doc.text
print(doc.text)
doc.text = gsub('\\n', ' ', doc.text)
print(doc.text)
doc.text = paste(doc.text, collapse = ' ')
doc.text
url = 'http://www.biblestudytools.com/job/'
doc.html = htmlTreeParse(url,
useInternal = TRUE)
# extract paragraphs and ublist
doc.text = unlist(xpathApply(doc.html, '//p', xmlValue))
print(doc.text)
# Replace all \n by spaces
doc.text = gsub('\\n', ' ', doc.text)
print(doc.text)
# doc.text = gsub('\\r', ' ', doc.text)
#  character vector
doc.text = paste(doc.text, collapse = ' ')
doc.text
url = 'http://adl.dk/adl_pub/pg/cv/ShowPgText.xsql?p_udg_id=137&p_sidenr=203&hist=fmO&nnoc=adl_pub'
doc.html = htmlTreeParse(url,
useInternal = TRUE)
doc.text = unlist(xpathApply(doc.html, '//p', xmlValue))
print(doc.text)
doc.text = gsub('\\n', ' ', doc.text)
print(doc.text)
doc.text = paste(doc.text, collapse = ' ')
print(doc.text)
library(data.table)
mydat <- fread('http://www.stats.ox.ac.uk/pub/datasets/csb/ch11b.dat')
mydat <- fread('http://adl.dk/adl_pub/pg/cv/AsciiPgVaerk2.xsql?nnoc=adl_pub&p_udg_id=137&p_vaerk_id=12469')
head(mydat)
url = 'http://adl.dk/adl_pub/pg/cv/AsciiPgVaerk2.xsql?nnoc=adl_pub&p_udg_id=137&p_vaerk_id=12469'
filename.v = paste(dd,'/data/sometxt.txt',sep="")
filename.v = paste(wd,'/data/sometxt.txt',sep="")
filename.v
download.file('http://www.gutenberg.org/cache/epub/10/pg10.txt', destfile = filename.v)
download.file(url, destfile = filename.v)
